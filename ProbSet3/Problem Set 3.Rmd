---
title: "Problem Set 3"
author: "Ian Sims"
date: "February 19, 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
set.seed(470670)
```

Load packages:

```{r echo=FALSE, error=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(lattice)
library(gapminder)
library(GGally)
library(NHANES)
library(broom)
library(BSDA)
library(coin)
library(reshape2)
library(gtools)
library(dplyr)
library(data.table)
library(alr4)
library(knitr)
library(carData)
library(moderndive)
```

## 1. (5 points.) Using the data set BGSgirls in package alr4:

**(a) Fit a linear regression model to predict girls' weight at age 18 (variable WT18) using weight at age 2 (WT2) and weight at age 9 (WT9) as the regressors. Display the resulting model in a format that someone who has not used R can understand.**

```{r}
m.wghts = lm(WT18 ~ WT2 + WT9, data = BGSgirls)
tidy(m.wghts)
```

This linear regression produces the model: WT18 = 34.26 - .97WT2 + 1.2WT9

**(b) The model with both WT2 and WT9 as the regressors has a negative coefficient for WT2. A friend sees this and says, "The negative sign means that girls who are heavier than average at age 2 will usually be heavier than average at age 18." Patiently explain why your friend is mistaken, and give a correct interpretation of the negative sign.**

Actually a negative coefficient implies a negative relationship to the response variable. In this case if a person has a higher weight at age 2 the model predicts they will have a lower weight at age 18. Though this shouldn't be relied on too much from this model since this model contains two predictor variables. If we were to run a linear model just using the age 2 weight we might get a different coefficient if there is not independence between WT2 and WT9.

**(c) The model with both WT2 and WT9 as the regressors has a coefficient of 1.2 for WT9. A friend sees this and says, "If two girls have a one pound difference in weight at age 9, the model predicts they'll have a 1.2 difference in weight at age 18." Is your friend correct? Why or why not?**

This would be true based on this model, assuming that both the girls had the same weight at age 2. Again this shouldn't be relied on too much considering there are two predictor variables that are likely not independent. If WT9 was modeled independenlty, the coeeficient could change.

## 2. (10 points.) The data set MinnLand in package alr4 contains data on "nearly every farm sale" in six economic regions in Minnesota from 2002 to 2011. Suppose we wish to model how sale price per acre (acrePrice) depends on year. Since sales price per acre is strongly right-skewed, we'll take log(acrePrice) as the response in our regressions.

**(a) Fit a linear regression model to predict log(acrePrice) from year alone, taking year as a continuous variable. Write down the regression equation you obtain.**

```{r}
m.price = lm(log(acrePrice) ~ year, data = MinnLand)
tidy(m.price)
```

The regresion equation is: log(acrePrice) = -193.88 + 0.10*year

**(b) Fit a regression model to predict log(acrePrice) from year alone, taking year as a factor. State the coefficient for the year 2008, and explain what this coefficient means.**

```{r}
mnlnd = MinnLand
mnlnd$year.fctr = as.factor(MinnLand$year)
#head(model.matrix(acrePrice ~ year.fctr, mnlnd), 10)
m.price.fctr = lm(log(acrePrice) ~ year.fctr, data = mnlnd)
summary(m.price.fctr)
```

The coefficient for the log(acrePrice) for 2008 is 0.68. This means that the estimated average log(acrePrice) for 2008 is 7.27 + .68 or 7.95. Which means the estimated average acrePrice for 2008 is: $2835.58.

**(c) Each of these two models can be used to (retrospectively) predict the expected log of sale price per acre from 2002 to 2011. Plot these predictions for the two models, and describe the differences.**

```{r}
plot(Effect("year", m.price))
plot(Effect("year.fctr", m.price.fctr))
```

The linear model that uses year as a continuos variable predicts a perfectly linear increase over time. The linear model based on year as a factor shows more variation over time. For example the latest four years of data show considerable flattening.

**(d) Which of these two models fits the data better? Support your answer using graphs or otherwise.**

```{r}
mnlnd$logAcrePrice = log(mnlnd$acrePrice)
mnlnd_grp = mnlnd %>%
              group_by(year) %>%
              dplyr::summarize(Mean_Log_acrePrice = mean(logAcrePrice, na.rm=TRUE))
plot(Mean_Log_acrePrice ~ year, data = mnlnd_grp)
title(main = "Actual Sample Data")
plot(Effect("year", m.price))
plot(Effect("year.fctr", m.price.fctr))
```

The first graph plots the average log(acrePrice) by year from the sample data. The second graph show the linear model with year as a continuous variable. The third plot shows the linear model with year as a factor. The factored model definitely seems to more closely resemble the actual sample experience.

Also given each year is very likely not independent, considering the linear model with year as continuos variable is problematic.

## 3. (10 points.) The data set Moore in the package carData contains data from an experiment to see how conformity with someone else's opinion was related to the other person's status. Subjects were paired with a partner of either high or low status; the partners were secretly collaborators of the investigators. On 40 key questions, the partners were told to disagree with the subjects. The experimenters counted the number of times each subject "conformed" by changing their opinion to agree with their partner. Each subject was also (presumably before the experiment) given a questionnaire to measure their authoritarianism, as authoritarianism could potentially affect how the subject reacted to disagreement.

## The variables in the data set are:**

## . conformity: number of conforming responses-could potentially be 0 to 40; observed values ranged from 4 to 24
## . partner.status: a factor: high or low 
## . fscore: authoritarianism score-observed values ranged from 15 to 68

## The data frame also includes fcategory, a categorized version of fscore; ignore this.

**(a) Show that there's evidence that partner.status affects conformity. (This might not require any regression. . . )**

```{r}
plot(conformity ~ partner.status, data = Moore)
```

Just looking at a simple plot of partner.status to conformity shows there are distinct differences both in the average conformity and the spread of the individual partner.status values over conformity. It looks like there is evidence to suspect that partner.status affects conformity.

**(b) Does the effect of partner.status differ for people with different fscores? One way to look at this is to fit a linear model with conformity as the response and fscore, partner.status, and their interaction as regressors. Fit this model, give the P-value, and explain what the P-value means and what it tells you about whether the effect of partner.status differs for people with different fscores.**

```{r}
m.conformity = lm(conformity ~ partner.status + fscore + partner.status:fscore, data = Moore)
get_regression_table(m.conformity)
```

The P-Value for the interaction coefficient for fscore and partner.status is 0.01. In essence, the P-Values tell you the effect of adding additional terms to the model. This is a low P-Value which suggest that adding this interaction term does seem significant. This suggests that the effect of partner.status does differ for people with different fscores.

**(c) A broader question is how the effect of partner.status differs for people with different fscore. This is perhaps easiest to study graphically. Using your model in (b), make predictions for conformity for people with fscores ranging from 15 to 68, for both the high status and low status treatments. Plot these predictions on the same graph, clearly distinguishing between the lines for the high and low status groups (e.g. by color.) Assuming your model is close to right, what does this graph tell you about how the effect of partner.status differs for people with different fscores?**

```{r}
m.conformity.df = augment(m.conformity)
m.conformity.df.filt = m.conformity.df[which(m.conformity.df$fscore >= 15 & m.conformity.df$fscore <= 68), ]
ggplot(m.conformity.df.filt, aes(x = fscore, y = .fitted, color = partner.status)) + geom_line()
```

There is a clear difference in how the effect of partner.status differs for people with different fscores. We see that when partner.status is high the predicted conformity decreases as the fscore increases. When partner.status is low the predicted conformity actually increased with higher fscores. 

## 4. (10 points.) The data set cakes contains data from a baking experiment using packaged cake mix. The response, Y, is a "palatability score" (higher is tastier.) The explanatory variables are X1, baking time in minutes, and X2, baking temperature in degrees Fahrenheit. (Ignore the block variable.)

**(a) Show graphically that it is not appropriate to model expected palatability score as a linear function of X1 and X2. Explain why we should have known this even before we looked at the data.**

```{r}
ggplot(cakes, aes(X2, X1)) +
    geom_jitter(position = position_jitter(width = .1))
```

When plotting the data points with X1 and X2 on the axis, we can see a clear pattern. These two variables have seem to have a correlation and therefore it is not appropriate to model expected palatability as a linear function of both variables.

It is fairly intuitive to assume there is a relationship between cooking time and oven tempature.

**(b) Fit a model to predict palatability score as the sum of quadratic functions of baking time and baking temperature. (For simplicity, we recommend you do not fit any interaction.) Display the fitted model graphically, e.g. through colored or faceted plots.**

```{r}
m.palatability = lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2), data = cakes)
m.palatability.df = augment(m.palatability)
ggplot(m.palatability.df, aes(x = X2, y = .fitted)) + geom_line() + facet_wrap(~ X1, labeller = label_both) + ylab("Palatability") + xlab("Baking Temp (F)") + ggtitle("Expected Palatability by Baking Time and Baking Temp")
```

**(c) For how long and at what temperature should you bake a cake using this mix to maximize the predicted palatability? (Hint: Recall from Calc I that a quadratic ax2 + bx + c is maximized at ???b/(2a) if a is negative.)**

```{r}
m.palatability = lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2), data = cakes)
rslts = tidy(m.palatability)
rslts
max_X1 = ( - rslts[2, 2]) / (2 * rslts[4, 2])
max_X1
max_X2 = ( - rslts[3, 2]) / (2 * rslts[5, 2])
max_X2
```

The baking time and tempature for the predicted maximum palatablility are 36.2 minutes and 354 degrees F, repsectively.

## 5. (10 points.) Returning to the MinnLand data set, one subject the data was collected to answer was the relationship between sale price per acre and crpPct, the percentage of the land enrolled in the Conservation Reserve Program. However, there are many potential confounding variables associated with crpPct that could affect sale prices. For example, land in the Conservation Reserve Program is disproportionately in northwest Minnesota, and sale prices in northwest Minnesota tend to be lower than in the rest of the state for reasons that may have less to do with the program than with negative temperatures in the winter. One way to study this would be to fit models that include both crpPct and region as predictors. However, it is not clear a priori whether an interaction between crpPct and region will help.

**(a) Fit a linear regression model to predict log(acrePrice) from crpPct and region, with no interaction. State the coefficient of crpPct in this model, and explain what this coefficient tells you about the relationship between crpPct and log(acrePrice).**

```{r}
m.acrePrice = lm(log(acrePrice) ~ crpPct + region, data = MinnLand)
summary(m.acrePrice)
```

Based on this model the coefficient for crpPct is near zero, which suggest that there isn't a relationship between crpPct and acrePrice.

**(b) Fit a regression model to predict log(acrePrice) from crpPct and region with an interaction. Explain what this model tells you about the relationship between crpPct and log(acrePrice).**

```{r}
m.acrePrice.intct = lm(log(acrePrice) ~ crpPct + region + crpPct:region, data = MinnLand)
summary(m.acrePrice.intct)
```

Including the interaction term again shows that all of the coefficients for interactions by region are close to zero. This, again suggests that there isn't a relationship between crpPct and acrePrice.

**(c) Perform an ANOVA to compare your models from parts (a) and (b). State the P-value that you get, and explain what, if anything, this P-value tells you.**

```{r}
anova(m.acrePrice, m.acrePrice.intct)
```

The P-Value is 0.002, which is very low. This suggest that there is evidence that the addition of the interaction term does positively contribute to the model.

**(d) Your ANOVA in part (c) made certain assumptions. Check the residuals of your model from (b) to see if these assumptions are close to satisfied.**

```{r}
m.acrePrice.intct = lm(log(acrePrice) ~ crpPct + region + crpPct:region, data = MinnLand)
m.acrePrice.intct.df = augment(m.acrePrice.intct)
ggplot(m.acrePrice.intct.df, aes(x = .fitted, y = .resid)) + geom_point()
```

ANOVA assumes heteroskedacticity of the residuals. Plotting the fitted values against the residual there are definite differences particularly at higher fitted values. This is an indication that the assumption does not hold.

## 6. (10 points.) The data set BigMac2003 in alr4 gives the price of a Big Mac in 2003 (BigMac), measured in minutes of labor required to buy one, in 69 cities. Of the many potential explanatory variables in the data set, FoodIndex, a measure of food prices (relative to a baseline where Zurich is 100), both logically makes sense as a predictor and has a fairly strong correlation with BigMac. We thus wish to first try a model to predict BigMac from FoodIndex, but these variables may require transformation.

**(a) Choose interpretable transformations to apply to FoodIndex and BigMac, such that the relationship between the transformed variables is approximately linear. (Note that you may choose "no transformation" for either variable.) Justify your choice using graphs or otherwise.**

```{r}
ggplot(BigMac2003, aes(x = FoodIndex, y = BigMac)) + geom_point()
ggplot(BigMac2003, aes(x = FoodIndex, y = log(BigMac))) + geom_point()
ggplot(BigMac2003, aes(x = log(FoodIndex), y = log(BigMac))) + geom_point()

m.bigmac = lm(log(BigMac) ~ log(FoodIndex), data = BigMac2003)
m.bigmac.df = augment(m.bigmac)
ggplot(m.bigmac.df, aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth(method = "gam", formula = y ~ s(x))

```

The first graphs plots the actual values of FoodIndex to BigMac. This shows a defintie right-skewdness. This suggest a ptoential log transformation. A log transformation is also am easily interpretable transformation. Apply a log transformation to the BigMac response variable (graph 2) helps to remove some of the skewness. However there does still seem to be a nonlinear trend in this data. The third graph includes a log transformation of both BigMac and Food index. This definitely seems like a more linear trend.

The final graph is a plot of the residuals based on a linear model applied to the log transformation of both variables. The residula plot confirms that these transformations do produce a nice linerarity.

**(b) The model can straightforwardly be improved by adding another predictor. Fit a better model that predicts the transformed BigMac variable from FoodIndex and one other variable. Convince the grader that your model is an improvement. (Your model may include complex regressors such as interactions if you wish.)**

After exploring the data associated with BigMac2003, it was determined that a reasonable addition to this model would be the TeachNI ("Primary teacher's net income, 1000s of US dollars"). This seems reasonble as the BigMac price is likely a function of overall food prices and the cost of labor.

```{r}
ggplot(BigMac2003, aes(x = TeachNI, y = log(BigMac))) + geom_point()
ggplot(BigMac2003, aes(x = log(TeachNI), y = log(BigMac))) + geom_point()

m.bigmac = lm(log(BigMac) ~ log(FoodIndex), data = BigMac2003)
m.bigmac.plus = lm(log(BigMac) ~ log(FoodIndex) + log(TeachNI), data = BigMac2003)
anova(m.bigmac, m.bigmac.plus)

m.bigmac.plus.df  = augment(m.bigmac.plus)
ggplot(m.bigmac.plus.df, aes(x = .fitted, y = .resid)) + geom_point()

m.bigmac.plus2 = lm(log(BigMac) ~ log(FoodIndex) + log(TeachNI) + log(FoodIndex):log(TeachNI), data = BigMac2003)
anova(m.bigmac.plus, m.bigmac.plus2)
```

The first graph considers the relationship between TeachNI and the log of BigMac. Again we see some left-skewdness. Applying an additional log transfomation to TeachNI (second graph), produces a more linear relationship.

Fitting a model that includes the log transformations for FoodIndex and TeachNI and performing an anova test prduces a P-Value very near zero which does suggest the additional variable improves the model. Plotting the residuals for the added filed model (graph 3) also demonstrates that the ANOVA assumption of heteroskedacticity is fairly reasonable.

Finally, adding an interaction term for FoodIndex and TeachNI and running an ANOVA against the model with the non-interaction prodices a P-Value of .73, which suggests that addding the interaction term does not improve the model.

**(c) Using numbers, graphs, and words, explain what your improved model tells you about how the price of Big Macs relates to the Food Index and your other explanatory variable.**

```{r}
m.bigmac.plus = lm(log(BigMac) ~ log(FoodIndex) + log(TeachNI), data = BigMac2003)
summary(m.bigmac.plus)

ggplot(BigMac2003, aes(x = log(FoodIndex), y = log(BigMac))) + geom_point()
ggplot(BigMac2003, aes(x = log(TeachNI), y = log(BigMac))) + geom_point()
```

Looking at the coefficients produced by this enhanced model, the relationship between both FoodIndex and TechNI is negatively correlated with BigMac price. This makes sense when looking at the scatterplots of the actual amaple data. We see that as FoodIndex and TeachNI increase the BigMac price decreases.

## 7. (5 points.) The data set BGSall in alr4 gives measurements on all subjects of the Berkeley Guidance Study, both male and female. Our goal is to find the model that best predicts height at age 18 (HT18 gives this height in cm) using measurements available at age 9: Sex, WT2, HT2, WT9, HT9, LG9, and ST9. See ?BGSall for definitions of all these variables. Find the best predictive model you can. You may not transform HT18 but you may transform any of the predictors. You may also consider interactions and higher-order terms. AIC isn't the be-all and end-all, but I managed to get a model with an AIC of 708.1 without looking too hard, so your model's AIC should get close to that. In addition, you should give some measure of how large you would expect the prediction errors if your model was applied to individuals similar to those in the data set (children born in California in 1928-29.)

```{r}
var1 = c("HT18", "Sex", "WT2", "HT2", "WT9", "HT9", "LG9", "ST9")
summary(BGSall[,var1])
scatterplotMatrix(BGSall[,var1],smooth = F, regLine = F, diagonal = F)

dd1 = powerTransform(cbind(WT2, HT2, WT9, HT9, LG9, ST9) ~ 1, BGSall)
summary(dd1)

m.ht18 = lm(HT18 ~ WT9 + HT9, data = BGSall)
m.ht18.intct = lm(HT18 ~ WT9 + HT9 + WT9:HT9, data = BGSall)
m.ht18.plus = lm(HT18 ~ WT9 + HT9 + LG9 + ST9, data = BGSall)
m.ht18.plus2 = lm(HT18 ~ WT9 + HT9 + LG9 + ST9 + WT9:LG9, data = BGSall)

anova(m.ht18, m.ht18.intct)
anova(m.ht18, m.ht18.plus)
anova(m.ht18.plus, m.ht18.plus2)

summary(m.ht18.plus)

AIC(m.ht18.plus2)

```

The scatterplots of each of these variables shows a fair amount of linearity with transformation. This is confimred by performing the power transformation test which suggests that the only term that could benefit from transfromation is the HT2. However, due to the probable correlation between the age 2 variables and the age 9 variables, we chose to exclude the age 2 variables from the model. It also makes mroe intuitive sense that age 9 variables will be more powerful when predicting a factor related to age 18.

Starting with a simple model that includes only WT9 and HT9 we compare this to more complex models using ANOVA. Adding an interaction term between WT9 and HT9 produced an ANOVA P-Value of 0.93, suggesting the addition of the interaction term did not improve the model.

Next we compared the simple model to a model that includes all variables except the age 2 variables. Comparing these models using ANOVA produced a P-VALU close to zero, suggesting these additional variables do improve the model.

Finally, we added an interaction term between WT9 and LG9 (maybe an intuitive relationship) and compared this using ANOVA to previous model which produce a P-Value of 0.53. This suggests this interaction term didn't improve the model.

The best model we produces seemed to be a simple linear model using the valriables: WT9, HT9, LG9 and ST9. with no transformations, as follows:

```{r}
m.ht18.plus = lm(HT18 ~ WT9 + HT9 + LG9 + ST9, data = BGSall)

summary(m.ht18.plus)
```

Looking at the predicted residuals we see:

```{r}
m.ht18.plus.df = augment(m.ht18.plus)
ggplot(m.ht18.plus.df, aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth(method = "gam", formula = y ~ s(x))

```














